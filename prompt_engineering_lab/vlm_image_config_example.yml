# Example configuration for vlm_image_tester.py
#
# Usage:
#   python vlm_image_tester.py --config vlm_image_config_example.yml
#
# Notes:
# - Images are automatically loaded from the "examples_to_use/" folder next to vlm_image_tester.py.
# - CLI flags override these values when provided.
# - mode: "single" or "all". If "single", set which VLM via "vlm".
# - vlm: one of [phi, tiny, qwen] (used only when mode == single)
# - prompt: your instruction to the VLMs

mode: single
vlm: phi
# prompt: |
#   You are a careful driving assistant. Describe the scene and recommend a safe driving action for the Duckiebot.

# prompt: |
#     What action should be taken by the vehicle in this situation? 
#     Provide a decision based on the current state of the environment. 
#     Describe what you see, the action to take, and why.

# prompt: |
#   Describe the image in detail. Focus on the environment, road, obstacles, vehicles,
#   pedestrians, and any relevant details that help understand the scene.


# ---------------------------------------------------------------------------
# (Optional) Full structured schema prompt matching examples_to_use/vlms_json_labels.json
# Uncomment and replace the simpler prompt above if you want richer outputs.
# ---------------------------------------------------------------------------
# prompt: |
#   You are a driving scene assistant. After analizing the image given, OUTPUT ONLY a single JSON object (no commentary) with these keys:
#   {
#     "obstacle_type": "None|Vehicle|Pedestrian|Static",
#     "lane_position": "Left|Center|Right|Off Track",
#     "pedestrian_presence": "None|Near",
#     "collision_warning": true|false,
#     "intersection_ahead": true|false,
#     "is_night_time": true|false,
#     "road_type": "Urban|Rural|Under Construction",
#     "obstacle_distance": "Near|Moderate|Far|None"
#   }
#   Rules: Use only allowed categorical values exactly; booleans must be true/false; if unsure choose the closest valid category; output only JSON.

prompt: |
  You are an expert autonomous-driving PERCEPTION system analyzing a single image from a car camera in a virtual driving simulation.

  Your task is to describe what is visible in the image by selecting the most appropriate value for each category below.  
  Use ONLY visible evidence from the image â€” do not infer beyond what is clearly shown.

  Respond STRICTLY in the following JSON format and with NO additional text or explanation:

  {
    "Vulnerable Road User (VRU)": ["None", "Single", "Multiple", "Unknown"],
    "vehicle": ["None", "Single", "Multiple", "Unknown"],
    "daylight": ["Day", "Night", "Unknown"],
    "lane_markers": ["None", "RightOnly", "LeftOnly", "LeftAndRight", "Unknown"],
    "road_edge": ["None", "RightOnly", "LeftOnly", "LeftAndRight", "Unknown"],
    "context_road": ["Urban", "Rural", "Highway", "Roadworks", "Unknown"],
    "context_junction": ["NoJunctionAhead", "JunctionAhead", "RoundaboutAhead", "Unknown"],
    "context_lane": ["InLaneCorrectDirection", "InLaneWrongDirection", "OutOfLane", "OffRoad", "Unknown"],
    "context_collidables": [
      "None",
      "CollisionRelevantObstaclePresent",
      "CollisionRelevantVehiclePresent",
      "CollisionRelevantVRUPresent",
      "Unknown"
    ],
    "risk_collision": ["None", "CollissionImminent", "CollisionRiskHigh", "CollisionRiskLow", "Unknown"]
  }
